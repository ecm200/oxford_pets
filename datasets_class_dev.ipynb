{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0da3747a036187680e2b34a8786029d6a50aba197a7c22b09ad53a2cc8b995665",
   "display_name": "Python 3.8.8 64-bit ('py38_pytorch181_cu111_clearml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from cub_tools.transforms import makeDefaultTransforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = \"data/annotations/list.txt\"\n",
    "img_dir = \"data/images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = pd.read_csv(annotations_file, header=None, skiprows=6, delim_whitespace=' ', names=['Class Name ID','Class ID','Species ID','Breed ID'])\n",
    "img_labels['Class Name'] = img_labels['Class Name ID'].str.rsplit('_', n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Class Name ID  Class ID  Species ID  Breed ID         Class Name\n",
       "0           Abyssinian_100         1           1         1         Abyssinian\n",
       "1           Abyssinian_101         1           1         1         Abyssinian\n",
       "2           Abyssinian_102         1           1         1         Abyssinian\n",
       "3           Abyssinian_103         1           1         1         Abyssinian\n",
       "4           Abyssinian_104         1           1         1         Abyssinian\n",
       "...                    ...       ...         ...       ...                ...\n",
       "7344  yorkshire_terrier_96        37           2        25  yorkshire_terrier\n",
       "7345  yorkshire_terrier_97        37           2        25  yorkshire_terrier\n",
       "7346  yorkshire_terrier_98        37           2        25  yorkshire_terrier\n",
       "7347  yorkshire_terrier_99        37           2        25  yorkshire_terrier\n",
       "7348   yorkshire_terrier_9        37           2        25  yorkshire_terrier\n",
       "\n",
       "[7349 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class Name ID</th>\n      <th>Class ID</th>\n      <th>Species ID</th>\n      <th>Breed ID</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abyssinian_100</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Abyssinian</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abyssinian_101</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Abyssinian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abyssinian_102</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Abyssinian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abyssinian_103</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Abyssinian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abyssinian_104</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Abyssinian</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7344</th>\n      <td>yorkshire_terrier_96</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7345</th>\n      <td>yorkshire_terrier_97</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7346</th>\n      <td>yorkshire_terrier_98</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7347</th>\n      <td>yorkshire_terrier_99</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7348</th>\n      <td>yorkshire_terrier_9</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>yorkshire_terrier</td>\n    </tr>\n  </tbody>\n</table>\n<p>7349 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7349"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = pd.DataFrame(np.arange(0,len(img_labels['Class Name'].unique()),1), columns=['class_id'], index=img_labels['Class Name'].unique())['class_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "class_names['Abyssinian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'tools')\n",
    "from tools.data import OxfordPetsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = makeDefaultTransforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OxfordPetsDataset(annotations_file=\"data/annotations/trainval.txt\", img_dir=\"data/images\", skiprows=0, transform=transforms['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.data import create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "***********************************************\n**            DATASET SUMMARY                **\n***********************************************\ntrain  size::  3680  images\ntest  size::  3669  images\nNumber of classes::  37\n***********************************************\n[INFO] Created data loaders.\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = create_dataloaders(\n",
    "    data_transforms=transforms, \n",
    "    data_dir=img_dir, \n",
    "    batch_size=1, \n",
    "    num_workers=4, \n",
    "    train_file='data/annotations/trainval.txt', \n",
    "    test_file='data/annotations/test.txt', \n",
    "    shuffle={'train' : True, 'test' : False}, \n",
    "    test_batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "97  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1398  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1399  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1400  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1401  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1402  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1403  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1404  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1405  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1406  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1407  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1408  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1409  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1410  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1411  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1412  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1413  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1414  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1415  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1416  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1417  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1418  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1419  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1420  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1421  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1422  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1423  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1424  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1425  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1426  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1427  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1428  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1429  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1430  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1431  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1432  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1433  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1434  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1435  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1436  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1437  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1438  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1439  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1440  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1441  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1442  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1443  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1444  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1445  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1446  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1447  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1448  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1449  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1450  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1451  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1452  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1453  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1454  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "\n",
      "\n",
      "idx:: 1580  Image Path:: data/images/shiba_inu_131.jpgidx:: 1210  Image Path:: data/images/pomeranian_113.jpgidx:: 2138  Image Path:: data/images/Bengal_185.jpgidx:: 1703  Image Path:: data/images/staffordshire_bull_terrier_107.jpg\n",
      "\n",
      "\n",
      "\n",
      "idx:: 3205  Image Path:: data/images/Russian_Blue_177.jpg\n",
      "idx:: 1648  Image Path:: data/images/Sphynx_104.jpgidx:: 1698  Image Path:: data/images/staffordshire_bull_terrier_102.jpgidx:: 2148  Image Path:: data/images/Birman_148.jpg\n",
      "\n",
      "\n",
      "idx:: 129  Image Path:: data/images/american_pit_bull_terrier_127.jpgidx:: 284  Image Path:: data/images/Bengal_131.jpg\n",
      "\n",
      "idx:: 1285  Image Path:: data/images/pug_137.jpg\n",
      "idx:: 3084  Image Path:: data/images/pug_14.jpg\n",
      "idx:: 3246  Image Path:: data/images/saint_bernard_15.jpg\n",
      "idx:: 2387  Image Path:: data/images/chihuahua_186.jpgidx:: 3210  Image Path:: data/images/Russian_Blue_181.jpg\n",
      "\n",
      "idx:: 3  Image Path:: data/images/Abyssinian_103.jpgidx:: 1959  Image Path:: data/images/american_pit_bull_terrier_158.jpgidx:: 237  Image Path:: data/images/beagle_137.jpg\n",
      "\n",
      "idx:: 2757  Image Path:: data/images/keeshond_166.jpg\n",
      "\n",
      "idx:: 1683  Image Path:: data/images/Sphynx_145.jpg\n",
      "idx:: 3028  Image Path:: data/images/Persian_20.jpg\n",
      "idx:: 100  Image Path:: data/images/american_pit_bull_terrier_100.jpgidx:: 2643  Image Path:: data/images/havanese_153.jpg\n",
      "idx:: 1860  Image Path:: data/images/Abyssinian_15.jpg\n",
      "idx:: 2736  Image Path:: data/images/keeshond_147.jpg\n",
      "\n",
      "idx:: 645  Image Path:: data/images/english_cocker_spaniel_145.jpg\n",
      "idx:: 2577  Image Path:: data/images/german_shorthaired_184.jpg\n",
      "idx:: 3409  Image Path:: data/images/shiba_inu_177.jpgidx:: 2916  Image Path:: data/images/miniature_pinscher_174.jpg\n",
      "idx:: 143  Image Path:: data/images/american_pit_bull_terrier_13.jpg\n",
      "\n",
      "idx:: 3345  Image Path:: data/images/scottish_terrier_159.jpgidx:: 1347  Image Path:: data/images/Russian_Blue_101.jpg\n",
      "idx:: 989  Image Path:: data/images/leonberger_13.jpg\n",
      "idx:: 1376  Image Path:: data/images/Russian_Blue_131.jpg\n",
      "idx:: 2312  Image Path:: data/images/British_Shorthair_176.jpg\n",
      "idx:: 2561  Image Path:: data/images/german_shorthaired_16.jpg\n",
      "\n",
      "idx:: 367  Image Path:: data/images/Bombay_116.jpgidx:: 1778  Image Path:: data/images/wheaten_terrier_12.jpg\n",
      "\n",
      "idx:: 1867  Image Path:: data/images/Abyssinian_168.jpgidx:: 2901  Image Path:: data/images/miniature_pinscher_160.jpg\n",
      "\n",
      "idx:: 780  Image Path:: data/images/great_pyrenees_131.jpgidx:: 998  Image Path:: data/images/Maine_Coon_102.jpg\n",
      "\n",
      "idx:: 3508  Image Path:: data/images/Sphynx_188.jpgidx:: 910  Image Path:: data/images/keeshond_113.jpg\n",
      "\n",
      "idx:: 592  Image Path:: data/images/Egyptian_Mau_143.jpgidx:: 2955  Image Path:: data/images/newfoundland_168.jpgidx:: 1761  Image Path:: data/images/wheaten_terrier_114.jpg\n",
      "\n",
      "\n",
      "idx:: 140  Image Path:: data/images/american_pit_bull_terrier_137.jpgidx:: 3579  Image Path:: data/images/staffordshire_bull_terrier_1.jpg\n",
      "idx:: 2269  Image Path:: data/images/boxer_16.jpg\n",
      "idx:: 2479  Image Path:: data/images/english_cocker_spaniel_186.jpgidx:: 3131  Image Path:: data/images/Ragdoll_153.jpg\n",
      "\n",
      "\n",
      "idx:: 220  Image Path:: data/images/beagle_120.jpg\n",
      "idx:: 1038  Image Path:: data/images/Maine_Coon_147.jpgidx:: 2204  Image Path:: data/images/Bombay_157.jpg\n",
      "idx:: 1034  Image Path:: data/images/Maine_Coon_143.jpg\n",
      "idx:: 1107  Image Path:: data/images/newfoundland_110.jpg\n",
      "idx:: 2943  Image Path:: data/images/newfoundland_157.jpgidx:: 11  Image Path:: data/images/Abyssinian_110.jpg\n",
      "\n",
      "\n",
      "idx:: 3642  Image Path:: data/images/yorkshire_terrier_157.jpg\n",
      "Batch:: 1455  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1456  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1457  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1458  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1459  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1460  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1461  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1462  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1463  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1464  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1465  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1466  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1467  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1468  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1469  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1470  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1471  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1472  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1473  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1474  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1475  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1476  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1477  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1478  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1479  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1480  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1481  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1482  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1483  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1484  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1485  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1486  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1487  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1488  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1489  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1490  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1491  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1492  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1493  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1494  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1495  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1496  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1497  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1498  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1499  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1500  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1501  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1502  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1503  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1504  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1505  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1506  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1507  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1508  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1509  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1510  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1511  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1512  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1513  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "idx:: 1431  Image Path:: data/images/saint_bernard_132.jpgidx:: 2051  Image Path:: data/images/beagle_153.jpg\n",
      "idx:: 3033  Image Path:: data/images/pomeranian_148.jpgidx:: 1217  Image Path:: data/images/pomeranian_11.jpg\n",
      "\n",
      "\n",
      "idx:: 658  Image Path:: data/images/english_setter_111.jpg\n",
      "idx:: 2368  Image Path:: data/images/chihuahua_169.jpgidx:: 2600  Image Path:: data/images/great_pyrenees_15.jpg\n",
      "\n",
      "idx:: 331  Image Path:: data/images/Birman_129.jpg\n",
      "idx:: 869  Image Path:: data/images/japanese_chin_121.jpg\n",
      "idx:: 2923  Image Path:: data/images/miniature_pinscher_180.jpgidx:: 859  Image Path:: data/images/japanese_chin_112.jpg\n",
      "\n",
      "idx:: 1011  Image Path:: data/images/Maine_Coon_116.jpgidx:: 3353  Image Path:: data/images/scottish_terrier_166.jpgidx:: 3467  Image Path:: data/images/Siamese_195.jpg\n",
      "\n",
      "\n",
      "idx:: 436  Image Path:: data/images/boxer_134.jpg\n",
      "idx:: 126  Image Path:: data/images/american_pit_bull_terrier_124.jpgidx:: 575  Image Path:: data/images/Egyptian_Mau_124.jpg\n",
      "idx:: 3634  Image Path:: data/images/yorkshire_terrier_14.jpg\n",
      "\n",
      "idx:: 2144  Image Path:: data/images/Bengal_190.jpgidx:: 65  Image Path:: data/images/american_bulldog_114.jpg\n",
      "idx:: 1361  Image Path:: data/images/Russian_Blue_115.jpg\n",
      "\n",
      "idx:: 1087  Image Path:: data/images/miniature_pinscher_138.jpgidx:: 2427  Image Path:: data/images/Egyptian_Mau_186.jpg\n",
      "idx:: 2116  Image Path:: data/images/Bengal_164.jpg\n",
      "\n",
      "idx:: 574  Image Path:: data/images/Egyptian_Mau_123.jpgidx:: 3311  Image Path:: data/images/samoyed_173.jpgidx:: 147  Image Path:: data/images/american_pit_bull_terrier_143.jpg\n",
      "idx:: 2092  Image Path:: data/images/beagle_191.jpg\n",
      "\n",
      "\n",
      "idx:: 3137  Image Path:: data/images/Ragdoll_160.jpgidx:: 2415  Image Path:: data/images/Egyptian_Mau_172.jpg\n",
      "Batch:: 1514  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1515  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1516  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1517  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1518  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1519  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1520  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1521  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1522  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1523  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1524  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1525  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1526  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1527  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1528  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1529  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1530  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1531  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1532  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1533  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1534  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1535  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1536  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1537  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1538  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1539  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1540  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1541  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1542  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1543  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n",
      "Batch:: 1544  Images Batch Size:: torch.Size([1, 3, 224, 224])  Labels Batch Size:: torch.Size([1])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/datadrive/drive0/projects/image_classification/oxford_pets/tools/data.py\", line 36, in __getitem__\n    image = self.transform(image)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 60, in __call__\n    img = t(img)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 221, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py\", line 336, in normalize\n    tensor.sub_(mean).div_(std)\nRuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4b16a77366d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batch:: {}  Images Batch Size:: {}  Labels Batch Size:: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/datadrive/drive0/projects/image_classification/oxford_pets/tools/data.py\", line 36, in __getitem__\n    image = self.transform(image)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 60, in __call__\n    img = t(img)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 221, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/home/edmorris/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py\", line 336, in normalize\n    tensor.sub_(mean).div_(std)\nRuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0\n"
     ]
    }
   ],
   "source": [
    "for batch, iteration in enumerate(iter(train_loader)):\n",
    "    print('Batch:: {}  Images Batch Size:: {}  Labels Batch Size:: {}'.format(batch, iteration[0].shape, iteration[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "125*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cub_tools.data import create_dataloaders as cub_create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cub_train_loader, cub_val_loader = cub_create_dataloaders(\n",
    "    data_transforms=transforms,\n",
    "    data_dir='../caltech_birds/data/images', \n",
    "    batch_size=16,\n",
    "    num_workers=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(cub_train_loader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for batch, iteration in enumerate(iter(cub_train_loader)):\n",
    "    print('Batch:: {}  Images Batch Size:: {}  Labels Batch Size:: {}'.format(batch, iteration[0].shape, iteration[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}